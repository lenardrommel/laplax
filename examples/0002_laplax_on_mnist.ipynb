{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data and model and train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the tutorial by downloading and setting up a dataloader for `MNIST`. We will use a simple `flax.nnx` model for the training. The data + model setup and training closely follows the `flax.nnx` [documentation](https://flax.readthedocs.io/en/latest/mnist_tutorial.html) to stress the flexible post-hoc abilities of `laplax` (and, of course, Laplace Approximations in general)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define constants\n",
    "train_steps = 2200\n",
    "eval_every = 200\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "# Load MNIST datasets\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=4,\n",
    "    prefetch_factor=2,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=val_batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=4,\n",
    "    prefetch_factor=2,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "\n",
    "def format_batch(batch):\n",
    "    return {\"input\": batch[0].permute(0, 2, 3, 1).numpy(), \"target\": batch[1].numpy()}\n",
    "\n",
    "\n",
    "def get_infinite_train_iter():\n",
    "    \"\"\"Creates an infinite iterator over the training data.\"\"\"\n",
    "    while True:\n",
    "        for batch in train_loader:\n",
    "            yield format_batch(batch)\n",
    "\n",
    "\n",
    "# Create training iterator that yields for exactly train_steps\n",
    "train_iter = islice(get_infinite_train_iter(), train_steps)\n",
    "num_training_samples = len(train_dataset)\n",
    "\n",
    "\n",
    "# For the test dataset\n",
    "def get_test_iter(loader):\n",
    "    for batch in loader:\n",
    "        yield format_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "from flax import nnx\n",
    "\n",
    "\n",
    "class CNN(nnx.Module):\n",
    "    \"\"\"A simple CNN model.\"\"\"\n",
    "\n",
    "    def __init__(self, *, rngs: nnx.Rngs):\n",
    "        self.conv1 = nnx.Conv(1, 32, kernel_size=(3, 3), padding=\"VALID\", rngs=rngs)\n",
    "        self.conv2 = nnx.Conv(32, 32, kernel_size=(3, 3), padding=\"VALID\", rngs=rngs)\n",
    "        self.conv3 = nnx.Conv(32, 64, kernel_size=(3, 3), padding=\"VALID\", rngs=rngs)\n",
    "        self.avg_pool1 = partial(nnx.avg_pool, window_shape=(2, 2), strides=(2, 2))\n",
    "        self.avg_pool2 = partial(nnx.avg_pool, window_shape=(3, 3), strides=(1, 1))\n",
    "        self.linear1 = nnx.Linear(64, 10, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.avg_pool1(nnx.relu(self.conv1(x)))\n",
    "        x = self.avg_pool1(nnx.relu(self.conv2(x)))\n",
    "        x = self.avg_pool2(nnx.relu(self.conv3(x)))\n",
    "        x = x.flatten()\n",
    "        x = self.linear1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = CNN(rngs=nnx.Rngs(0))\n",
    "\n",
    "\n",
    "# Create forward function with vmap\n",
    "@nnx.vmap(in_axes=(None, 0), out_axes=0)\n",
    "def forward(model: CNN, x):\n",
    "    return model(x)\n",
    "\n",
    "\n",
    "# Visualize it\n",
    "# nnx.display(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "learning_rate = 3e-4\n",
    "momentum = 0.9\n",
    "\n",
    "optimizer = nnx.Optimizer(model, optax.adamw(learning_rate, momentum))\n",
    "metrics = nnx.MultiMetric(\n",
    "    accuracy=nnx.metrics.Accuracy(),\n",
    "    loss=nnx.metrics.Average(\"loss\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup training step functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model: CNN, batch):\n",
    "    logits = forward(model, batch[\"input\"])\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "        logits=logits, labels=batch[\"target\"]\n",
    "    ).mean()\n",
    "    return loss, logits\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model: CNN, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(model, batch)\n",
    "    metrics.update(loss=loss, logits=logits, labels=batch[\"target\"])  # In-place updates\n",
    "    optimizer.update(grads)  # In-place updates\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def eval_step(model: CNN, metrics: nnx.MultiMetric, batch):\n",
    "    loss, logits = loss_fn(model, batch)\n",
    "    metrics.update(loss=loss, logits=logits, labels=batch[\"target\"])  # In-place updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_accuracy\": [],\n",
    "    \"test_loss\": [],\n",
    "    \"test_accuracy\": [],\n",
    "}\n",
    "\n",
    "for step, batch in enumerate(train_iter):\n",
    "    # Run the optimization for one step and make a stateful update to the following:\n",
    "    # - The train state's model parameters\n",
    "    # - The optimizer state\n",
    "    # - The training loss and accuracy batch metrics\n",
    "    train_step(model, optimizer, metrics, batch)\n",
    "\n",
    "    if step > 0 and (step % eval_every == 0 or step == train_steps - 1):\n",
    "        # One training epoch has passed.\n",
    "        # Log the training metrics.\n",
    "        for metric, value in metrics.compute().items():  # Compute the metrics.\n",
    "            metrics_history[f\"train_{metric}\"].append(value)  # Record the metrics.\n",
    "        metrics.reset()  # Reset the metrics for the test set.\n",
    "\n",
    "        # Compute the metrics on the test set after each training epoch.\n",
    "        for test_batch in get_test_iter(test_loader):\n",
    "            eval_step(model, metrics, test_batch)\n",
    "\n",
    "        # Log the test metrics.\n",
    "        for metric, value in metrics.compute().items():\n",
    "            metrics_history[f\"test_{metric}\"].append(value)\n",
    "        metrics.reset()  # Reset the metrics for the next training epoch.\n",
    "\n",
    "        print(\n",
    "            f\"[train] step: {step}, \"\n",
    "            f\"loss: {metrics_history['train_loss'][-1]}, \"\n",
    "            f\"accuracy: {metrics_history['train_accuracy'][-1] * 100}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"[test] step: {step}, \"\n",
    "            f\"loss: {metrics_history['test_loss'][-1]}, \"\n",
    "            f\"accuracy: {metrics_history['test_accuracy'][-1] * 100}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check model calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have followed along the standard MNIST tutorial from `flax.nnx`. Now, we want to check the calibration of the model, i.e. whether the probabilities it assigns to each class label represents its confidence. A good score for this is the ECE (see e.g. [Mucs√°nyi2023](https://trustworthyml.io/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import jax.numpy as jnp\n",
    "from plotting import create_proportion_diagram, create_reliability_diagram\n",
    "\n",
    "from laplax.eval.metrics import calculate_bin_metrics, correctness\n",
    "\n",
    "NUM_BINS = 15\n",
    "\n",
    "# Collect predictions and targets from test dataset\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "\n",
    "for batch in get_test_iter(test_loader):\n",
    "    # Get predictions for this batch\n",
    "    predictions = jax.nn.softmax(forward(model, batch[\"input\"]), axis=1)\n",
    "    all_predictions.append(predictions)\n",
    "    all_targets.append(batch[\"target\"])\n",
    "\n",
    "\n",
    "# Concatenate all batches\n",
    "predictions = jnp.concatenate(all_predictions, axis=0)\n",
    "targets = jnp.concatenate(all_targets, axis=0)\n",
    "\n",
    "# Calculate confidence and correctness\n",
    "max_prob = predictions.max(axis=-1)\n",
    "correctness_float = correctness(pred=predictions, target=targets).astype(jnp.float32)\n",
    "\n",
    "print(f\"Accuracy: {correctness_float.mean():.4f}\")\n",
    "\n",
    "# Calculate bin metrics\n",
    "bin_proportions, bin_confidences, bin_accuracies = calculate_bin_metrics(\n",
    "    confidence=max_prob, correctness=correctness_float, num_bins=NUM_BINS\n",
    ")\n",
    "\n",
    "# Plot the reliability diagram\n",
    "create_reliability_diagram(\n",
    "    bin_confidences=bin_confidences,\n",
    "    bin_accuracies=bin_accuracies,\n",
    "    num_bins=NUM_BINS,\n",
    ")\n",
    "\n",
    "# Plot the proportion diagram\n",
    "create_proportion_diagram(\n",
    "    bin_proportions=bin_proportions,\n",
    "    num_bins=NUM_BINS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Laplace Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create the GGN matrix-vector product. As the GGN has 679,730,993,764 entries in this case, the naive representation of the dense matrix would take approximately 2.718 TB of VRAM. Therefore, it is crucial to represent this matrix-vector product _implicitly_, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.curv import create_ggn_mv\n",
    "\n",
    "# Create GGN\n",
    "graph_def, params = nnx.split(model)\n",
    "\n",
    "\n",
    "def model_fn(input, params):\n",
    "    return nnx.call((graph_def, params))(input)[0]\n",
    "\n",
    "\n",
    "train_batch = next(get_infinite_train_iter())\n",
    "ggn_mv = create_ggn_mv(\n",
    "    model_fn,\n",
    "    params,\n",
    "    train_batch,\n",
    "    loss_fn=\"cross_entropy\",\n",
    "    num_total_samples=num_training_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the GGN matrix-vector product above to obtain a low-rank approximation of the GGN. Even though the dense GGN cannot be represented in memory, its low-rank approximation for a sufficiently low rank remains tractable to hold in memory. Having access to the low-rank GGN terms, we can then efficiently invert an isotropically dampened version of it which is the weight-space covariance matrix of our Laplace approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.curv.cov import create_posterior_fn\n",
    "\n",
    "# Create Posterior\n",
    "posterior_fn = create_posterior_fn(\n",
    "    \"low_rank\",\n",
    "    mv=ggn_mv,\n",
    "    layout=params,\n",
    "    key=jax.random.key(20),\n",
    "    maxiter=20,\n",
    "    mv_jittable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need a way to represent the model's uncertainty in its output space, as decisions (such as abstaining from prediction) are made based on the model output, not on the weight space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.eval.metrics import expected_calibration_error\n",
    "from laplax.eval.pushforward import (\n",
    "    lin_mc_pred_act,\n",
    "    lin_pred_mean,\n",
    "    lin_setup,\n",
    "    set_lin_pushforward,\n",
    ")\n",
    "\n",
    "prior_arguments = {\"prior_prec\": 10000.0}\n",
    "pushforward_fns = [\n",
    "    lin_setup,\n",
    "    lin_pred_mean,\n",
    "    lin_mc_pred_act,\n",
    "]\n",
    "\n",
    "pushforward_fn = jax.jit(\n",
    "    jax.vmap(\n",
    "        set_lin_pushforward(\n",
    "            model_fn=model_fn,\n",
    "            mean_params=params,\n",
    "            posterior_fn=posterior_fn,\n",
    "            prior_arguments=prior_arguments,\n",
    "            pushforward_fns=pushforward_fns,\n",
    "            key=jax.random.key(0),\n",
    "            num_samples=30,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "confidences_map = []\n",
    "correctnesses_map = []\n",
    "confidences_pred = []\n",
    "correctnesses_pred = []\n",
    "\n",
    "n_batches = len(test_loader)\n",
    "# std_mean = 0\n",
    "\n",
    "\n",
    "pushforward_fn = jax.jit(\n",
    "    jax.vmap(\n",
    "        set_lin_pushforward(\n",
    "            model_fn=model_fn,\n",
    "            mean_params=params,\n",
    "            posterior_fn=posterior_fn,\n",
    "            prior_arguments=prior_arguments,\n",
    "            pushforward_fns=pushforward_fns,\n",
    "            key=jax.random.key(0),\n",
    "            num_samples=30,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "confidences_map = []\n",
    "correctnesses_map = []\n",
    "confidences_pred = []\n",
    "correctnesses_pred = []\n",
    "\n",
    "n_batches = len(test_loader)\n",
    "\n",
    "for i, batch in enumerate(get_test_iter(test_loader)):\n",
    "    print(f\"{i + 1}/{n_batches}\", end=\"\\r\")\n",
    "    results = pushforward_fn(batch[\"input\"])\n",
    "    target = batch[\"target\"]\n",
    "    map_ = results[\"map\"]\n",
    "    pred_act = results[\"mc_pred_act\"]\n",
    "\n",
    "    # std_mean = (i * std_mean + jnp.mean(jnp.sqrt(results[\"pred_var\"]))) / (i + 1)\n",
    "\n",
    "    confidences_map.append(jnp.max(jax.nn.softmax(map_, axis=1), axis=1))\n",
    "    correctnesses_map.append(correctness(pred=map_, target=target).astype(jnp.float32))\n",
    "    confidences_pred.append(jnp.max(pred_act, axis=1))\n",
    "    correctnesses_pred.append(\n",
    "        correctness(pred=pred_act, target=target).astype(jnp.float32)\n",
    "    )\n",
    "\n",
    "confidences_map = jnp.concatenate(confidences_map, axis=0)\n",
    "correctnesses_map = jnp.concatenate(correctnesses_map, axis=0)\n",
    "confidences_pred = jnp.concatenate(confidences_pred, axis=0)\n",
    "correctnesses_pred = jnp.concatenate(correctnesses_pred, axis=0)\n",
    "\n",
    "ece_map = expected_calibration_error(\n",
    "    confidence=confidences_map, correctness=correctnesses_map, num_bins=NUM_BINS\n",
    ")\n",
    "ece_pred = expected_calibration_error(\n",
    "    confidence=confidences_pred, correctness=correctnesses_pred, num_bins=NUM_BINS\n",
    ")\n",
    "\n",
    "print(f\"MAP ECE: {ece_map:.4f}\")\n",
    "print(f\"MAP acc: {correctnesses_map.mean():.4f}\")\n",
    "print(f\"Laplace ECE: {ece_pred:.4f}\")\n",
    "print(f\"Laplace acc: {correctnesses_pred.mean():.4f}\")\n",
    "# print(f\"Laplace std mean: {std_mean:.4f}\")\n",
    "\n",
    "\n",
    "# Calculate bin metrics for Laplace\n",
    "bin_proportions_pred, bin_confidences_pred, bin_accuracies_pred = calculate_bin_metrics(\n",
    "    confidence=confidences_pred, correctness=correctnesses_pred, num_bins=NUM_BINS\n",
    ")\n",
    "\n",
    "# Plot the reliability diagram\n",
    "create_reliability_diagram(\n",
    "    bin_confidences=bin_confidences_pred,\n",
    "    bin_accuracies=bin_accuracies_pred,\n",
    "    num_bins=NUM_BINS,\n",
    ")\n",
    "\n",
    "# Plot the proportion diagram\n",
    "create_proportion_diagram(\n",
    "    bin_proportions=bin_proportions_pred,\n",
    "    num_bins=NUM_BINS,\n",
    ")\n",
    "\n",
    "# Calculate bin metrics for MAP\n",
    "bin_proportions_map, bin_confidences_map, bin_accuracies_map = calculate_bin_metrics(\n",
    "    confidence=confidences_map, correctness=correctnesses_map, num_bins=NUM_BINS\n",
    ")\n",
    "\n",
    "# Plot the reliability diagram\n",
    "create_reliability_diagram(\n",
    "    bin_confidences=bin_confidences_map,\n",
    "    bin_accuracies=bin_accuracies_map,\n",
    "    num_bins=NUM_BINS,\n",
    ")\n",
    "\n",
    "# Plot the proportion diagram\n",
    "create_proportion_diagram(\n",
    "    bin_proportions=bin_proportions_map,\n",
    "    num_bins=NUM_BINS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same evaluation using the Metrics API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup two versions of the pushforward functions.\n",
    "pushforward_fn = set_lin_pushforward(\n",
    "    model_fn=model_fn,\n",
    "    mean_params=params,\n",
    "    posterior_fn=posterior_fn,\n",
    "    prior_arguments=prior_arguments,\n",
    "    pushforward_fns=pushforward_fns,\n",
    "    key=jax.random.key(0),\n",
    "    num_samples=30,\n",
    ")\n",
    "pushforward_fn_jit = jax.jit(pushforward_fn)\n",
    "pushforward_fn_jit_vmap = jax.jit(jax.vmap(pushforward_fn))\n",
    "\n",
    "\n",
    "# Define the metrics function (ideally with batch dimension)\n",
    "def confidences_map(map_, **kwargs):\n",
    "    del kwargs\n",
    "    return jnp.max(jax.nn.softmax(map_, axis=-1), axis=-1)\n",
    "\n",
    "\n",
    "def confidences_pred(pred_act, **kwargs):\n",
    "    del kwargs\n",
    "    return jnp.max(pred_act, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.eval import apply_fns, evaluate_metrics_on_generator, transfer_entry\n",
    "\n",
    "results = evaluate_metrics_on_generator(\n",
    "    pushforward_fn_jit,\n",
    "    get_test_iter(test_loader),\n",
    "    metrics=[\n",
    "        transfer_entry([\"pred_mean\", \"map\", \"mc_pred_act\"]),\n",
    "        apply_fns(\n",
    "            confidences_map,\n",
    "            confidences_pred,\n",
    "            correctness,\n",
    "            names=[\"confidences_map\", \"confidences_pred\", \"correctness_map\"],\n",
    "            map_=\"map\",\n",
    "            pred_act=\"mc_pred_act\",\n",
    "            pred=\"map\",\n",
    "            target=\"target\",\n",
    "        ),\n",
    "        apply_fns(\n",
    "            correctness,\n",
    "            names=[\"correctness_pred\"],\n",
    "            pred=\"mc_pred_act\",\n",
    "            target=\"target\",\n",
    "        ),\n",
    "    ],\n",
    "    reduce=jnp.concatenate,\n",
    "    has_batch=True,\n",
    ")\n",
    "\n",
    "confidences_map_val = results[\"confidences_map\"].astype(jnp.float32)\n",
    "correctness_map_val = results[\"correctness_map\"].astype(jnp.float32)\n",
    "confidences_pred_val = results[\"confidences_pred\"].astype(jnp.float32)\n",
    "correctness_pred_val = results[\"correctness_pred\"].astype(jnp.float32)\n",
    "\n",
    "ece_map = expected_calibration_error(\n",
    "    confidence=confidences_map_val, correctness=correctness_map_val, num_bins=NUM_BINS\n",
    ")\n",
    "ece_pred = expected_calibration_error(\n",
    "    confidence=confidences_pred_val, correctness=correctness_pred_val, num_bins=NUM_BINS\n",
    ")\n",
    "\n",
    "print(f\"MAP ECE: {ece_map:.4f}\")\n",
    "print(f\"MAP acc: {correctness_map_val.mean():.4f}\")\n",
    "print(f\"Laplace ECE: {ece_pred:.4f}\")\n",
    "print(f\"Laplace acc: {correctness_pred_val.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all functions (pushforward and metrics) support already a batch dimension, then we can set `has_batch` to `False`, which might be faster in execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.eval import apply_fns, transfer_entry\n",
    "\n",
    "results = evaluate_metrics_on_generator(\n",
    "    pushforward_fn_jit_vmap,\n",
    "    get_test_iter(test_loader),\n",
    "    metrics=[\n",
    "        transfer_entry([\"pred_mean\", \"map\", \"mc_pred_act\"]),\n",
    "        apply_fns(\n",
    "            confidences_map,\n",
    "            confidences_pred,\n",
    "            correctness,\n",
    "            # correctness_pred_act,\n",
    "            names=[\n",
    "                \"confidences_map\",\n",
    "                \"confidences_pred\",\n",
    "                \"correctness_map\",\n",
    "                # \"correctness_pred\"\n",
    "            ],\n",
    "            map_=\"map\",\n",
    "            pred_act=\"mc_pred_act\",\n",
    "            pred=\"map\",\n",
    "            target=\"target\",\n",
    "        ),\n",
    "        apply_fns(\n",
    "            correctness,\n",
    "            names=[\"correctness_pred\"],\n",
    "            pred=\"mc_pred_act\",\n",
    "            target=\"target\",\n",
    "        ),\n",
    "    ],\n",
    "    reduce=jnp.concatenate,\n",
    "    has_batch=False,\n",
    "    # If all functions handles batch dimensions properly, then setting false works.\n",
    ")\n",
    "\n",
    "confidences_map_val = results[\"confidences_map\"].astype(jnp.float32)\n",
    "correctness_map_val = results[\"correctness_map\"].astype(jnp.float32)\n",
    "confidences_pred_val = results[\"confidences_pred\"].astype(jnp.float32)\n",
    "correctness_pred_val = results[\"correctness_pred\"].astype(jnp.float32)\n",
    "\n",
    "ece_map = expected_calibration_error(\n",
    "    confidence=confidences_map_val, correctness=correctness_map_val, num_bins=NUM_BINS\n",
    ")\n",
    "ece_pred = expected_calibration_error(\n",
    "    confidence=confidences_pred_val, correctness=correctness_pred_val, num_bins=NUM_BINS\n",
    ")\n",
    "\n",
    "print(f\"MAP ECE: {ece_map:.4f}\")\n",
    "print(f\"MAP acc: {correctness_map_val.mean():.4f}\")\n",
    "print(f\"Laplace ECE: {ece_pred:.4f}\")\n",
    "print(f\"Laplace acc: {correctness_pred_val.mean():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
