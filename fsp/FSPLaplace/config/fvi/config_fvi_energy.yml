# Experiment selection
experiment:
  name: "hpo_regression" # toy_data_experiments, uci_regression, image_regression, ood_detection_regression, bandits, hpo_regression
  # hpo_classification, experiments_classification, image_classification
  sweep_id: "x296wlpu"

# Model selection
model:
  name: "FVI" # GFSVI, MFVI, GP, Laplace, TFSVI, FVI

fvi:
  neural_net:
    type: "MLP" # MLP, CNN1, CNN2 ------------------------------------------------------- Make sure this is the NN we want to use
    architecture: [50, 50]
    last_layer_vi: false
    activation_fn: "tanh"
    validation_freq: 100
    periodic_features: 

  likelihood:
    model: "Gaussian" # Gaussian, Categorical
    scale: 1.
    n_classes: 10

  # Training configuration
  training:
    mc_samples: 10
    nb_epochs: 30000
    lr: 0.001
    n_context_points: 400 # 100 for mnist, fmnist, cifar10 and svhn - 10 for full
    context_selection: "random" # random, grid
    patience: 2000
    pretrained_weights_path: ""
    
  # Prior 
  prior:
    kernel: "RBF" # RBF, Matern12, Matern32, Matern52, Polynomial_d2, Polynomial_d4, Empirical, Linear, Periodic, RationalQuadratic
    parameter_tuning: true
    nb_epochs: 1000
    batch_size: 500
    lr: 0.01
    alpha_eps: 0.001 # recommended
    parameters: {"lengthscale": 0.25, "variance": 0.5, "alpha": 4.3} 

# Dataset configuration 
data:
  name: "energy" 
  # ToyData: truncated_sine, GP_RBF, two_moons
  # UCI: boston, concrete, energy, kin8nm, naval, power, protein, wine, yacht, wave, denmark
  # Image: mnist, fashion_mnist, cifar10, svhn
  feature_dim: 2
  n_samples: 300
  batch_size: 1000
  k_folds: 5


image_regression: 
  n_img_samples: 10
  masked_pixels: 84 # out of 784 pixels. 
  image_idx: 0
  image_label: 9
  

bandits:
  name: "financial" # financial, mushroom, statlog, jester
  n_bandit_simulations: 5
  simulation_batch_size: 500 
  training_batch_size: 1000
